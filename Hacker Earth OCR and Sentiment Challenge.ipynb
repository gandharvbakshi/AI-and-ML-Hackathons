{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('C:\\\\Users\\\\Gandharv\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37-32\\\\Lib\\\\site-packages')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('vader_lexicon')\n",
    "import re\n",
    "import string\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import emoji\n",
    "import seaborn as sns\n",
    "#import cv2\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "TRAIN_PATH = 'C:\\\\AI Learning\\\\Hacker Earth Projects\\\\Pride challenge\\\\Data Files\\\\Dataset'\n",
    "\n",
    "tempFileList = os.listdir(TRAIN_PATH)\n",
    "trainFileList = []\n",
    "for f in tempFileList:\n",
    "    trainFileList.append(os.path.join(TRAIN_PATH,f))\n",
    "#print(len(trainFileList))\n",
    "\n",
    "sentimentList = []\n",
    "\n",
    "for i in range(0,len(trainFileList)):    \n",
    "    trialImage = Image.open(trainFileList[i])\n",
    "    sentence = pytesseract.image_to_string(trialImage)\n",
    "    sid_obj = SentimentIntensityAnalyzer() \n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence) \n",
    "    #print(\"Overall sentiment dictionary is : \", sentiment_dict) \n",
    "    #print(\"sentence was rated as \", sentiment_dict['neg']*100, \"% Negative\") \n",
    "    #print(\"sentence was rated as \", sentiment_dict['neu']*100, \"% Neutral\") \n",
    "    #print(\"sentence was rated as \", sentiment_dict['pos']*100, \"% Positive\") \n",
    "    #print(sentence, \" Sentence Overall Rated As \", sentiment_dict['compound']) \n",
    "    if sentiment_dict['compound'] >= 0.05 : \n",
    "        sentimentList.append(\"Positive\")\n",
    "        #print(\"Positive\") \n",
    "    elif sentiment_dict['compound'] <= - 0.05 : \n",
    "        sentimentList.append(\"Negative\") \n",
    "    else : \n",
    "        sentimentList.append(\"Random\") \n",
    "\n",
    "#print(sentimentList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values of the said array:\n",
      "[['Negative' 'Neutral' 'Positive']\n",
      " ['23' '167' '49']]\n",
      "239 239\n",
      "(239, 2)\n"
     ]
    }
   ],
   "source": [
    "#print(sentimentList)\n",
    "a = np.array(sentimentList)\n",
    "unique_elements, counts_elements = np.unique(a, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "print(len(tempFileList), len(sentimentList) )\n",
    "combinedSentiment = pd.DataFrame(np.vstack((tempFileList,sentimentList)))\n",
    "combinedSentiment = combinedSentiment.T\n",
    "print(combinedSentiment.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data.drop([\"tweet\"], axis = 1, inplace = True)\n",
    "combinedSentiment.to_csv(os.path.join(TRAIN_PATH,\"finalSubmission.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
