{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AB Sentiment Analysis 2 using BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c601a54a3605405f9cf52f7913eac72a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b5a98aba4efb4d728dc28a04aaa7545e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_739d8445340a4a30beee7049e81cf457",
              "IPY_MODEL_0da783ac92444eb0b753a145cb8e7105",
              "IPY_MODEL_3bebea9728254b909c10d42d2b842c03"
            ]
          }
        },
        "b5a98aba4efb4d728dc28a04aaa7545e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "739d8445340a4a30beee7049e81cf457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0644ac0cb7924cf89efb6d177e7b6d0f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cebd796b35314d04be9988d6e77fc08e"
          }
        },
        "0da783ac92444eb0b753a145cb8e7105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_61fd6efba7754f18ae73cb2295bdd65c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 798011,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 798011,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0cab6e0c6c3145389dc5a8252970bf61"
          }
        },
        "3bebea9728254b909c10d42d2b842c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_56a94a22007b4eb594c646fa3c301225",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 798k/798k [00:00&lt;00:00, 983kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0e3b3fe7152421db132ac2d559f3b54"
          }
        },
        "0644ac0cb7924cf89efb6d177e7b6d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cebd796b35314d04be9988d6e77fc08e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61fd6efba7754f18ae73cb2295bdd65c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0cab6e0c6c3145389dc5a8252970bf61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56a94a22007b4eb594c646fa3c301225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0e3b3fe7152421db132ac2d559f3b54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99793762054548c08f8a08535598e635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aa599d164c944531a51153a88d9a4e7b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a5c99c465ce84ead9dcf79801fc9f85e",
              "IPY_MODEL_97cf12a5fc9e4f15b72de647e25449b0",
              "IPY_MODEL_60ac361ff79a4961ac481fe60d64d244"
            ]
          }
        },
        "aa599d164c944531a51153a88d9a4e7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5c99c465ce84ead9dcf79801fc9f85e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d29614ca76ee45fdabedf929fa3e7c62",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eff823d567514c09a1d3edda2fae22c0"
          }
        },
        "97cf12a5fc9e4f15b72de647e25449b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7e9c2de20ddc4c3fba09e641bbadc4a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1382015,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1382015,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e70428aa8df40b38224ce90b2e5e2ca"
          }
        },
        "60ac361ff79a4961ac481fe60d64d244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_119408fd5abe42a4893fd19e901c34fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.38M/1.38M [00:01&lt;00:00, 1.38MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a9736e3aee24a8490bf501cfb20d282"
          }
        },
        "d29614ca76ee45fdabedf929fa3e7c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eff823d567514c09a1d3edda2fae22c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e9c2de20ddc4c3fba09e641bbadc4a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e70428aa8df40b38224ce90b2e5e2ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "119408fd5abe42a4893fd19e901c34fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a9736e3aee24a8490bf501cfb20d282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1e0542296cf427da9ddeb86768ee6db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3802615fd91e4ecca1ec179daa5c70b3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1afbb7aa25a2483c8209c4313d370f11",
              "IPY_MODEL_89ca3ca3236b440782ec8cce8a632e50",
              "IPY_MODEL_402e40ba01ad4dd5907e07e876d1e0e0"
            ]
          }
        },
        "3802615fd91e4ecca1ec179daa5c70b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1afbb7aa25a2483c8209c4313d370f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0c58dd0134c748dc9c9799d745c61477",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7637bb424b3e47e7871437089c2c9eb4"
          }
        },
        "89ca3ca3236b440782ec8cce8a632e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c7ed2ff1a3084b72ba86d58b30c8004a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7920,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7920,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87b98438c4e44383a557509a49ba4f58"
          }
        },
        "402e40ba01ad4dd5907e07e876d1e0e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_334e4067aa124dffb62b58f38fac7554",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7920/7920 [00:03&lt;00:00, 2352.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95aed824f4ff4e9a924ec050b406294b"
          }
        },
        "0c58dd0134c748dc9c9799d745c61477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7637bb424b3e47e7871437089c2c9eb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7ed2ff1a3084b72ba86d58b30c8004a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87b98438c4e44383a557509a49ba4f58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "334e4067aa124dffb62b58f38fac7554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95aed824f4ff4e9a924ec050b406294b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "761c21001fed463ab548f9d2efa4b2ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3b1ab31f05fb4988a4618c935750b381",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c497c19528d84eecbfab9f608e5c033d",
              "IPY_MODEL_ac5ea4af023b486a92cbeed2cc6f6878",
              "IPY_MODEL_b3f1c6a54a544104ac92ab144e77ba17"
            ]
          }
        },
        "3b1ab31f05fb4988a4618c935750b381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c497c19528d84eecbfab9f608e5c033d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_09ee52d6e59a47a9841d8aaf23ffcffd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_319d849a295f4e7f9160361d4bf29e85"
          }
        },
        "ac5ea4af023b486a92cbeed2cc6f6878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_35882b3befee48aaad2a3f70c36d5d55",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1953,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1953,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_31a4bd5d7e124c0a8778fee96b3db5ef"
          }
        },
        "b3f1c6a54a544104ac92ab144e77ba17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cd0a813cc5ca47459df6889aed11729f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1953/1953 [00:00&lt;00:00, 2374.55it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e012a26451654d2d993d5515bd5569ac"
          }
        },
        "09ee52d6e59a47a9841d8aaf23ffcffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "319d849a295f4e7f9160361d4bf29e85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35882b3befee48aaad2a3f70c36d5d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "31a4bd5d7e124c0a8778fee96b3db5ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd0a813cc5ca47459df6889aed11729f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e012a26451654d2d993d5515bd5569ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gandharvbakshi/AI-and-ML-Hackathons/blob/main/Sentiment%20Analysis%202%20(from%20a%20proprietary%20Analytics%20Vidhya%20Database)%20using%20BERT%20and%20XLNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPV6GD0oXtQk"
      },
      "source": [
        "# Objective\n",
        "\n",
        "In this notebook, we will fine-tune a pre-trained BERT model to perform sentiment analysis on a twitter data.\n",
        "\n",
        "# Table of Contents\n",
        "\n",
        "1. Setup\n",
        "  - Using Google Colab for training\n",
        "  - Installing the Hugging Face's Transformers Library\n",
        "2. Loading & Understanding BERT\n",
        "  - Download Pretrained BERT model\n",
        "  - Tokenization and Input Formatting\n",
        "  - Understanding Input and Output\n",
        "3. Preparing Data\n",
        "  - Loading and Reading Twitter Airline\n",
        "  - Text Cleaning\n",
        "  - Preparing Input and Output Data\n",
        "  - Training and Validation Data\n",
        "  - Define Dataloaders\n",
        "4. Model Finetuning\n",
        "  - Approach: Fine-Tuning Only Head\n",
        "  - Define Model Architecture\n",
        "  - Define Optimizer and Loss function\n",
        "  - Model Training and Evaluation\n",
        "  - Train the Model\n",
        "  - Model Evaluation \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLnXNGquujFX"
      },
      "source": [
        "# 1. Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5dWVBhsvBpB"
      },
      "source": [
        "## 1.1 Using Google Colab for training\n",
        "\n",
        "Google Colab offers free GPUs and TPUs! Since we are going to train a large neural network, it's best to take advantage of the GPU/TPU (in this case we'll attach a GPU), otherwise training will take a very long time.\n",
        "\n",
        "A GPU can be added by going to the menu and selecting:\n",
        "\n",
        "\n",
        "```\n",
        "Runtime -> Change Runtime -> GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3QUIh1DwGdK"
      },
      "source": [
        "We will identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plFhDqWS7IDl"
      },
      "source": [
        "#import torch library\n",
        "import torch\n",
        "\n",
        "# check GPU availability\n",
        "if torch.cuda.is_available():    \n",
        "    # select GPU    \n",
        "    device = torch.device(\"cuda\")\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qksck1C7e3I"
      },
      "source": [
        "# check GPU name\n",
        "if torch.cuda.is_available():    \n",
        "    # select GPU    \n",
        "    torch.cuda.get_device_name(0)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL4kE0e9xyl0"
      },
      "source": [
        "## 1.2. Installing the Hugging Face's Transformers Library\n",
        "\n",
        "Hugging Face 🤗 is the one of the most popular Natural Language Processing communities for deep learning researchers, hands-on practitioners and educators. It provides State of Art architectures for everyone.\n",
        "\n",
        "\n",
        "The Transformers library (formerly known as pytorch-transformers) provides a wide range of general-purpose architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, etc) for Natural Language Understanding (NLU) and Natural Language Generation (NLG) with a wide range of pretrained models in 100+ languages and deep interoperability between TensorFlow 2.0 and PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_jdjScBvG-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad8f1fbc-0284-4b9b-f47c-daee70320a69"
      },
      "source": [
        "#install hugging face transformers\n",
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1eLFxRkQL1R"
      },
      "source": [
        "# 2. Loading & Understanding BERT "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M1sab_G9bOl"
      },
      "source": [
        "##2.1 Download Pretrained BERT model\n",
        "\n",
        "We will use the uncased pre-trained version of the BERT base model. It was trained on lower-cased English text. \n",
        "\n",
        "You can find more pre-trained models here https://huggingface.co/transformers/pretrained_models.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZGp7pmiIa42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "129fc7f0-3af8-4e56-e630-4d45e01076af"
      },
      "source": [
        "from transformers import BertModel\n",
        "from transformers import XLNetConfig, XLNetModel, XLNetForSequenceClassification\n",
        "\n",
        "# download bert pretrained model\n",
        "#bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "#bert-large-uncased\n",
        "bert = BertModel.from_pretrained('bert-large-uncased')\n",
        "\n",
        "#trying XLNET \n",
        "XLNetModel = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels = 2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
            "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'logits_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NzkcvW6F5aE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ef1ee4f-eec2-4747-eab4-3a39759f8116"
      },
      "source": [
        "# print bert architecture\n",
        "print(bert)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 1024)\n",
            "    (token_type_embeddings): Embedding(2, 1024)\n",
            "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (12): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (13): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (14): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (15): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (16): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (17): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (18): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (19): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (20): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (21): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (22): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (23): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcJBvP5U_AEz",
        "outputId": "4b0cba48-2420-44dc-f32b-a3f8c86f83ca"
      },
      "source": [
        "print(XLNetModel)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XLNetForSequenceClassification(\n",
            "  (transformer): XLNetModel(\n",
            "    (word_embedding): Embedding(32000, 768)\n",
            "    (layer): ModuleList(\n",
            "      (0): XLNetLayer(\n",
            "        (rel_attn): XLNetRelativeAttention(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ff): XLNetFeedForward(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): XLNetLayer(\n",
            "        (rel_attn): XLNetRelativeAttention(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ff): XLNetFeedForward(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (2): XLNetLayer(\n",
            "        (rel_attn): XLNetRelativeAttention(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ff): XLNetFeedForward(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (3): XLNetLayer(\n",
            "        (rel_attn): XLNetRelativeAttention(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ff): XLNetFeedForward(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (4): XLNetLayer(\n",
            "        (rel_attn): XLNetRelativeAttention(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ff): XLNetFeedForward(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (5): XLNetLayer(\n",
            "        (rel_attn): XLNetRelativeAttention(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ff): XLNetFeedForward(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (6): XLNetLayer(\n",
            "        (rel_attn): XLNetRelativeAttention(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ff): XLNetFeedForward(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (7): XLNetLayer(\n",
            "        (rel_attn): XLNetRelativeAttention(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ff): XLNetFeedForward(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (8): XLNetLayer(\n",
            "        (rel_attn): XLNetRelativeAttention(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ff): XLNetFeedForward(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (9): XLNetLayer(\n",
            "        (rel_attn): XLNetRelativeAttention(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ff): XLNetFeedForward(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (10): XLNetLayer(\n",
            "        (rel_attn): XLNetRelativeAttention(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ff): XLNetFeedForward(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (11): XLNetLayer(\n",
            "        (rel_attn): XLNetRelativeAttention(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ff): XLNetFeedForward(\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (sequence_summary): SequenceSummary(\n",
            "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (first_dropout): Identity()\n",
            "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (logits_proj): Linear(in_features=768, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYGt3oSZ4fzZ"
      },
      "source": [
        "##2.2 Tokenization and Input Formatting\n",
        "\n",
        "**Download BERT Tokenizer**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd7iONki5NqP",
        "outputId": "f0c8286e-bc48-4d3f-8d0d-73e4dd88f767"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 4.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCZVXkA30cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "c601a54a3605405f9cf52f7913eac72a",
            "b5a98aba4efb4d728dc28a04aaa7545e",
            "739d8445340a4a30beee7049e81cf457",
            "0da783ac92444eb0b753a145cb8e7105",
            "3bebea9728254b909c10d42d2b842c03",
            "0644ac0cb7924cf89efb6d177e7b6d0f",
            "cebd796b35314d04be9988d6e77fc08e",
            "61fd6efba7754f18ae73cb2295bdd65c",
            "0cab6e0c6c3145389dc5a8252970bf61",
            "56a94a22007b4eb594c646fa3c301225",
            "a0e3b3fe7152421db132ac2d559f3b54",
            "99793762054548c08f8a08535598e635",
            "aa599d164c944531a51153a88d9a4e7b",
            "a5c99c465ce84ead9dcf79801fc9f85e",
            "97cf12a5fc9e4f15b72de647e25449b0",
            "60ac361ff79a4961ac481fe60d64d244",
            "d29614ca76ee45fdabedf929fa3e7c62",
            "eff823d567514c09a1d3edda2fae22c0",
            "7e9c2de20ddc4c3fba09e641bbadc4a2",
            "9e70428aa8df40b38224ce90b2e5e2ca",
            "119408fd5abe42a4893fd19e901c34fe",
            "9a9736e3aee24a8490bf501cfb20d282"
          ]
        },
        "outputId": "96b30551-dd9e-4aa4-d3fa-f2f9b5cd9d02"
      },
      "source": [
        "#importing fast \"BERT\" tokenizer\n",
        "from transformers import BertTokenizerFast\n",
        "from transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification\n",
        "\n",
        "# Load BERT tokenizer\n",
        "#tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "#tokenizer = BertTokenizerFast.from_pretrained('bert-large-uncased', do_lower_case=True)\n",
        "#XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
        "PRE_TRAINED_MODEL_NAME = 'xlnet-base-cased'\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
        "tokenizer"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c601a54a3605405f9cf52f7913eac72a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99793762054548c08f8a08535598e635",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreTrainedTokenizer(name_or_path='xlnet-base-cased', vocab_size=32000, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='left', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '<sep>', 'pad_token': '<pad>', 'cls_token': '<cls>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True), 'additional_special_tokens': ['<eop>', '<eod>']})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WosuQLl15olj"
      },
      "source": [
        "**Steps Followed for Input Formatting**\n",
        "\n",
        "1. Tokenization\n",
        "\n",
        "2. Special Tokens\n",
        "\n",
        "  * Prepend the `[CLS]` token to the start of the sequence.\n",
        "  * Append the `[SEP]` token to the end of the sequence.\n",
        "\n",
        "3. Pad sequences \n",
        "\n",
        "4. Converting tokens to integers\n",
        "\n",
        "5. Create Attention masks to avoid pad tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MBNXOU_BVj-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "868c434d-e382-4c14-db39-81b1ef474bff"
      },
      "source": [
        "#input text\n",
        "text = \"Jim Henson was a puppeteer\"\n",
        "\n",
        "sent_id = tokenizer.encode(text, \n",
        "                           # add [CLS] and [SEP] tokens\n",
        "                           add_special_tokens=True,\n",
        "                           # specify maximum length for the sequences                                  \n",
        "                           max_length = 10,\n",
        "                           truncation = True,\n",
        "                           # add pad tokens to the right side of the sequence\n",
        "                           pad_to_max_length='right')\n",
        "                           \n",
        "# print integer sequence\n",
        "print(\"Integer Sequence: {}\".format(sent_id))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Integer Sequence: [17, 2030, 98, 17, 6838, 672, 30, 24, 4, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH_fCLgKt9I-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85760c80-870f-44d0-af3e-827501117a3f"
      },
      "source": [
        "# convert integers back to text\n",
        "print(\"Tokenized Text:\",tokenizer.convert_ids_to_tokens(sent_id))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Text: ['[CLS]', 'jim', 'henson', 'was', 'a', 'puppet', '##eer', '[SEP]', '[PAD]', '[PAD]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIQRb3ghOufP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9249f57-c5b9-4469-eba0-58f4002c5059"
      },
      "source": [
        "# decode the tokenized text\n",
        "decoded = tokenizer.decode(sent_id)\n",
        "print(\"Decoded String: {}\".format(decoded))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded String: [CLS] jim henson was a puppeteer [SEP] [PAD] [PAD]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4HGTu_RAOof",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ab26c4e-2e23-4989-80f9-4f8ec5928a32"
      },
      "source": [
        "# mask to avoid performing attention on padding token indices. \n",
        "# mask values: 1 for tokens that are NOT MASKED, 0 for MASKED tokens.   \n",
        "att_mask = [int(tok > 0) for tok in sent_id]\n",
        "\n",
        "print(\"Attention Mask:\",att_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF2MqKaT69Iz"
      },
      "source": [
        "##2.3 Understanding Input and Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IcDHx93CJnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69154f83-1160-45bb-d414-0dd58cb6949d"
      },
      "source": [
        "# convert lists to tensors\n",
        "sent_id = torch.tensor(sent_id)\n",
        "att_mask = torch.tensor(att_mask)\n",
        "\n",
        "# reshaping tensor in form of (batch,text length)\n",
        "sent_id = sent_id.unsqueeze(0)\n",
        "att_mask = att_mask.unsqueeze(0)\n",
        "\n",
        "# reshaped tensor\n",
        "print(sent_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,  3958, 27227,  2001,  1037, 13997, 11510,   102,     0,     0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv3ebAJVBoMW"
      },
      "source": [
        "# pass integer sequence to bert model\n",
        "outputs = bert(sent_id, attention_mask=att_mask)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLtc7RRzzc0s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97df37bc-72a2-4db2-931d-f5f2c57f4b1b"
      },
      "source": [
        "## unpack the ouput of bert model\n",
        "\n",
        "# hidden states at each timestep\n",
        "all_hidden_states = outputs[0]\n",
        "# hidden states at first timestep ([CLS] token)\n",
        "cls_hidden_state = outputs[1]\n",
        "\n",
        "print(\"Shape of last hidden states:\",all_hidden_states.shape)\n",
        "print(\"Shape of CLS hidden state:\",cls_hidden_state.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of last hidden states: torch.Size([1, 10, 768])\n",
            "Shape of CLS hidden state: torch.Size([1, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6xTpvKwfSlW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "74420da5-0471-4724-a246-6cd3a5df142b"
      },
      "source": [
        "cls_hidden_state"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8767, -0.4109, -0.1220,  0.4494,  0.1945, -0.2698,  0.8316,  0.3127,\n",
              "          0.1178, -1.0000, -0.1561,  0.6677,  0.9891, -0.3451,  0.8812, -0.6753,\n",
              "         -0.3079, -0.5580,  0.4380, -0.4588,  0.5831,  0.9956,  0.4467,  0.2863,\n",
              "          0.3924,  0.6863, -0.7513,  0.9043,  0.9436,  0.8207, -0.6493,  0.3524,\n",
              "         -0.9919, -0.2295, -0.0742, -0.9936,  0.3698, -0.7558,  0.0792, -0.2218,\n",
              "         -0.8637,  0.4711,  0.9997, -0.4368,  0.0404, -0.3498, -1.0000,  0.2663,\n",
              "         -0.8711,  0.0508,  0.0505, -0.1635,  0.1716,  0.4363,  0.4330, -0.0333,\n",
              "         -0.0416,  0.2206, -0.2568, -0.6122, -0.5916,  0.2569, -0.2622, -0.9041,\n",
              "          0.3221, -0.2394, -0.2634, -0.3454, -0.0723,  0.0081,  0.8297,  0.2279,\n",
              "          0.1614, -0.6555, -0.2062,  0.3280, -0.4016,  1.0000, -0.0952, -0.9874,\n",
              "         -0.0401,  0.0717,  0.3675,  0.3373, -0.3710, -1.0000,  0.4479, -0.1722,\n",
              "         -0.9917,  0.2677,  0.4844, -0.2207, -0.3207,  0.3715, -0.2171, -0.2522,\n",
              "         -0.3071, -0.3161, -0.1988, -0.0860, -0.0114, -0.1982, -0.1799, -0.3221,\n",
              "          0.1751, -0.4442, -0.1570, -0.0434, -0.0893,  0.5717,  0.3112, -0.2900,\n",
              "          0.3305, -0.9430,  0.6061, -0.2984, -0.9873, -0.3956, -0.9926,  0.7857,\n",
              "         -0.1692, -0.2719,  0.9505,  0.5628,  0.2904, -0.1693,  0.1619, -1.0000,\n",
              "         -0.1696, -0.1534,  0.2513, -0.2857, -0.9846, -0.9638,  0.5565,  0.9200,\n",
              "          0.1805,  0.9995, -0.2122,  0.9391,  0.3246, -0.3937, -0.1248, -0.5209,\n",
              "          0.0519,  0.1141, -0.6463,  0.3529, -0.0322, -0.3837, -0.3796, -0.2830,\n",
              "          0.1280, -0.9191, -0.4201,  0.9145,  0.0713, -0.2455,  0.5212, -0.2642,\n",
              "         -0.3675,  0.8082,  0.2577,  0.2755, -0.0157,  0.3675, -0.3107,  0.4502,\n",
              "         -0.8224,  0.2841,  0.4360, -0.3193,  0.2165, -0.9851, -0.4444,  0.5759,\n",
              "          0.9878,  0.7531,  0.3384,  0.2003, -0.2602,  0.4695, -0.9561,  0.9855,\n",
              "         -0.1712,  0.2295,  0.1220, -0.1386, -0.8436, -0.3783,  0.8371, -0.3204,\n",
              "         -0.8457, -0.0473, -0.4219, -0.3593, -0.2186,  0.5282, -0.3149, -0.4375,\n",
              "         -0.0440,  0.9242,  0.9296,  0.7735, -0.3733,  0.3945, -0.9049, -0.2898,\n",
              "          0.2695,  0.2910,  0.1695,  0.9932, -0.3069, -0.1611, -0.8349, -0.9827,\n",
              "          0.1299, -0.8555, -0.0531, -0.6830,  0.3926,  0.2873, -0.1899,  0.2598,\n",
              "         -0.9201, -0.7455,  0.3943, -0.3955,  0.4015, -0.2341,  0.7593,  0.3421,\n",
              "         -0.6143,  0.5170,  0.8987,  0.1072, -0.6858,  0.6481, -0.2454,  0.8712,\n",
              "         -0.5958,  0.9936,  0.3404,  0.4972, -0.9452, -0.2347, -0.8748, -0.0154,\n",
              "         -0.1293, -0.5265,  0.4235,  0.4206,  0.3663,  0.7488, -0.4650,  0.9900,\n",
              "         -0.8695, -0.9701, -0.5203, -0.0900, -0.9914,  0.0978,  0.2844, -0.0424,\n",
              "         -0.4649, -0.4546, -0.9620,  0.8035,  0.2177,  0.9705, -0.0793, -0.7985,\n",
              "         -0.3436, -0.9537, -0.0035, -0.0945,  0.4291,  0.0391, -0.9602,  0.4497,\n",
              "          0.5135,  0.4913,  0.0608,  0.9948,  1.0000,  0.9810,  0.8865,  0.7961,\n",
              "         -0.9894, -0.5122,  1.0000, -0.8521, -1.0000, -0.9412, -0.6633,  0.3110,\n",
              "         -1.0000, -0.1468, -0.1235, -0.9465, -0.0891,  0.9796,  0.9700, -1.0000,\n",
              "          0.9324,  0.9259, -0.4503,  0.4591, -0.1785,  0.9819,  0.2285,  0.4423,\n",
              "         -0.2615,  0.4124, -0.5252, -0.8534,  0.0365, -0.0670,  0.8944,  0.1913,\n",
              "         -0.4782, -0.9402,  0.2293, -0.1581, -0.2440, -0.9604, -0.1924, -0.0555,\n",
              "          0.5484,  0.1915,  0.2038, -0.7367,  0.2698, -0.7307,  0.3715,  0.5640,\n",
              "         -0.9386, -0.5717,  0.3818, -0.2775,  0.1536, -0.9608,  0.9702, -0.3502,\n",
              "          0.1524,  1.0000,  0.3876, -0.9001,  0.2547,  0.1857,  0.0832,  1.0000,\n",
              "          0.3811, -0.9852, -0.4053,  0.2576, -0.3923, -0.4125,  0.9994, -0.1463,\n",
              "         -0.0428,  0.2818,  0.9899, -0.9923,  0.8351, -0.8563, -0.9634,  0.9617,\n",
              "          0.9268, -0.4224, -0.7369,  0.1318,  0.1107,  0.2294, -0.8914,  0.6082,\n",
              "          0.4665, -0.0720,  0.8555, -0.7973, -0.3478,  0.4201, -0.1762,  0.0761,\n",
              "          0.2823,  0.4571, -0.1350,  0.1190, -0.3509, -0.4039, -0.9556,  0.0262,\n",
              "          1.0000, -0.2164,  0.0569, -0.2296, -0.1003, -0.1827,  0.4036,  0.4715,\n",
              "         -0.3293, -0.8471, -0.0518, -0.8453, -0.9935,  0.6732,  0.2284, -0.1968,\n",
              "          0.9998,  0.5194,  0.2326,  0.1718,  0.7497, -0.0192,  0.4518, -0.0327,\n",
              "          0.9765, -0.3259,  0.3491,  0.7471, -0.3186, -0.3019, -0.5725,  0.0563,\n",
              "         -0.9206,  0.0572, -0.9589,  0.9565,  0.3109,  0.3348,  0.1635, -0.0619,\n",
              "          1.0000, -0.6020,  0.5309, -0.3723,  0.6636, -0.9851, -0.6789, -0.4312,\n",
              "         -0.1435, -0.0827, -0.2497,  0.1323, -0.9786, -0.0474, -0.0304, -0.9444,\n",
              "         -0.9927,  0.2508,  0.6172,  0.1679, -0.7980, -0.6078, -0.4906,  0.4646,\n",
              "         -0.1934, -0.9396,  0.5453, -0.3000,  0.4329, -0.3340,  0.4408, -0.2058,\n",
              "          0.8344,  0.1265, -0.0307, -0.2098, -0.8340,  0.7114, -0.7410,  0.0518,\n",
              "         -0.1481,  1.0000, -0.3100,  0.1461,  0.7011,  0.6334, -0.2857,  0.1618,\n",
              "          0.0966,  0.2955, -0.0981, -0.1832, -0.6208, -0.3013,  0.4337,  0.0283,\n",
              "         -0.2959,  0.7579,  0.4711,  0.3666, -0.0531,  0.0914,  0.9969, -0.2267,\n",
              "         -0.1165, -0.5533, -0.1262, -0.3575, -0.2124,  1.0000,  0.3679,  0.0604,\n",
              "         -0.9936, -0.1999, -0.9208,  0.9999,  0.8511, -0.8783,  0.5650,  0.2405,\n",
              "         -0.2859,  0.6935, -0.2598, -0.2655,  0.2893,  0.2862,  0.9774, -0.4575,\n",
              "         -0.9764, -0.5964,  0.3966, -0.9575,  0.9939, -0.5326, -0.2349, -0.4376,\n",
              "         -0.0250,  0.2574,  0.0274, -0.9762, -0.1582,  0.1821,  0.9811,  0.3014,\n",
              "         -0.3820, -0.9007, -0.1151,  0.3936, -0.0680, -0.9449,  0.9809, -0.9313,\n",
              "          0.2600,  1.0000,  0.3860, -0.5243,  0.2401, -0.4410,  0.3253, -0.1412,\n",
              "          0.5428, -0.9466, -0.2817, -0.3262,  0.4330, -0.2120, -0.2457,  0.7247,\n",
              "          0.2134, -0.3430, -0.6305, -0.1214,  0.4871,  0.7498, -0.2957, -0.1829,\n",
              "          0.1699, -0.1391, -0.9264, -0.4167, -0.2995, -0.9991,  0.6411, -1.0000,\n",
              "         -0.1510, -0.5473, -0.2219,  0.8075,  0.3862, -0.1392, -0.7206, -0.0710,\n",
              "          0.6995,  0.6656, -0.2889,  0.2902, -0.6951,  0.1622, -0.1298,  0.3182,\n",
              "          0.1694,  0.6526, -0.2735,  1.0000,  0.1370, -0.3043, -0.9189,  0.3041,\n",
              "         -0.2604,  1.0000, -0.7969, -0.9715,  0.2110, -0.5773, -0.7218,  0.2477,\n",
              "         -0.0304, -0.7015, -0.6577,  0.9111,  0.8219, -0.3693,  0.4537, -0.3062,\n",
              "         -0.3671,  0.0856,  0.1595,  0.9903,  0.2790,  0.8213, -0.2885, -0.0723,\n",
              "          0.9636,  0.2213,  0.6892,  0.2070,  1.0000,  0.3249, -0.8999,  0.2644,\n",
              "         -0.9700, -0.2610, -0.9228,  0.4016,  0.1170,  0.8570, -0.3587,  0.9672,\n",
              "          0.0667,  0.1108, -0.1840,  0.4711,  0.3127, -0.9391, -0.9892, -0.9908,\n",
              "          0.3962, -0.5013, -0.0640,  0.3811,  0.1530,  0.4712,  0.3781, -1.0000,\n",
              "          0.9466,  0.3529,  0.2077,  0.9735,  0.2019,  0.4726,  0.4248, -0.9892,\n",
              "         -0.9203, -0.3418, -0.2910,  0.6572,  0.5584,  0.8190,  0.4319, -0.4171,\n",
              "         -0.4697,  0.4653, -0.8583, -0.9940,  0.4802,  0.0740, -0.8986,  0.9559,\n",
              "         -0.4745, -0.1616,  0.4457,  0.1412,  0.8933,  0.8280,  0.4313,  0.2437,\n",
              "          0.6787,  0.9043,  0.8940,  0.9903, -0.2561,  0.6986, -0.0055,  0.3281,\n",
              "          0.6809, -0.9586,  0.1583,  0.0033, -0.2711,  0.3025, -0.1928, -0.9207,\n",
              "          0.5260, -0.2139,  0.5709, -0.2302,  0.1593, -0.4779, -0.1577, -0.7036,\n",
              "         -0.5208,  0.4676,  0.2335,  0.9372,  0.4775, -0.1995, -0.5655, -0.2336,\n",
              "          0.0798, -0.9315,  0.8288, -0.0946,  0.5294,  0.0223, -0.0744,  0.7821,\n",
              "          0.1236, -0.3705, -0.3958, -0.7528,  0.8145, -0.3204, -0.4786, -0.5135,\n",
              "          0.7306,  0.3208,  0.9981, -0.3959, -0.3492, -0.1118, -0.2872,  0.3596,\n",
              "         -0.1345, -1.0000,  0.2896,  0.2262,  0.1702, -0.3530,  0.1111, -0.0755,\n",
              "         -0.9565, -0.2658,  0.2530, -0.0490, -0.5834, -0.4616,  0.3937,  0.2329,\n",
              "          0.5620,  0.8138, -0.0288,  0.5621,  0.3811,  0.0852, -0.6049,  0.8452]],\n",
              "       grad_fn=<TanhBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQj1-E2pQY6H"
      },
      "source": [
        "#3. Preparing Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFGQamTe3ebu"
      },
      "source": [
        "\n",
        "##3.1 Loading and Reading Twitter Airline "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS15IXod09aE",
        "outputId": "b51deb83-8e42-4639-c02c-a1e959a60853"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpHLW3M3KJEk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9695efbe-b361-41d0-c37b-b1eef206645d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# increase the output column width\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "\n",
        "dataDir = '/content/drive/MyDrive/AI ML Projects/AB Course/Sentiment 2'\n",
        "# read CSV file\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/AI ML Projects/AB Course/Sentiment 2/train_2kmZucJ.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/AI ML Projects/AB Course/Sentiment 2/test_12QyDcx.csv')\n",
        "\n",
        "\n",
        "# print first 5 rows\n",
        "train_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>We love this! Would you go? #talk #makememories #unplug #relax #iphone #smartphone #wifi #connect... http://fb.me/6N3LsUpCu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>I'm wired I know I'm George I was made that way ;) #iphone #cute #daventry #home http://instagr.am/p/Li_5_ujS4k/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>What amazing service! Apple won't even talk to me about a question I have unless I pay them $19.95 for their stupid support!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                                                                                                                tweet\n",
              "0   1  ...     #fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone\n",
              "1   2  ...  Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/\n",
              "2   3  ...          We love this! Would you go? #talk #makememories #unplug #relax #iphone #smartphone #wifi #connect... http://fb.me/6N3LsUpCu\n",
              "3   4  ...                     I'm wired I know I'm George I was made that way ;) #iphone #cute #daventry #home http://instagr.am/p/Li_5_ujS4k/\n",
              "4   5  ...         What amazing service! Apple won't even talk to me about a question I have unless I pay them $19.95 for their stupid support!\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzLKBEuUKJAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf15ba25-7999-4776-bd87-ca198e9d5560"
      },
      "source": [
        "#shape of the dataframe\n",
        "train_df.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7920, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36CP54lLf2gA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9433b9f-0eb4-491c-dadb-5388d2f95b90"
      },
      "source": [
        "train_df['tweet'].sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127     Endless love #instagram #instagood #instadaily #instahub #instagood #photoofthaday #Iphone #iphone4 #D http://instagr.am/p/S00OMtqk6a/\n",
              "657           If you barely have any games out at all, why even release online multiplayer? #Sony #Multiplayer #Online #PS4 #Playstation4 #PSN\n",
              "2670                                              Hello to my new baby. #new #mobile #phone #samsung #note3 http://instagram.com/p/nkPjvazVZA/\n",
              "3386             Hello to my new baby Yey' early Christmas gift for myself #Blessed #Samsung #J7Prime https://www.instagram.com/p/BcWg4mMFqZs/\n",
              "6527       New Flipcover By Doutzen #Flipcover #Doutzen #Kroes #Samsung #S4 #Mini #Orange #WK #2014 #Summer http://instagram.com/p/nsCPbIriz_/\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GirJa9_sWJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd94b069-6edf-4942-d49c-e9bc477cb45a"
      },
      "source": [
        "# class distribution\n",
        "train_df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5894\n",
              "1    2026\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnWcEVUWIMGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb4cfa5d-bff3-4b71-a82b-f4e8af934182"
      },
      "source": [
        "# class distribution\n",
        "train_df['label'].value_counts(normalize = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.744192\n",
              "1    0.255808\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ArDZS9tVuPS"
      },
      "source": [
        "# saving the value counts to a list\n",
        "class_counts = train_df['label'].value_counts().tolist()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWWstFVe3x00"
      },
      "source": [
        "##3.2 Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ol7s5sTGUgj"
      },
      "source": [
        "#library for pattern matching\n",
        "import re\n",
        "\n",
        "#define a function for text cleaning\n",
        "def preprocessor(text):\n",
        "  \n",
        "  #convering text to lower case\n",
        "  text = text.lower()\n",
        "\n",
        "  #remove user mentions\n",
        "  text = re.sub(r'@[A-Za-z0-9]+','',text)           \n",
        "  \n",
        "  #remove hashtags\n",
        "  #text = re.sub(r'#[A-Za-z0-9]+','',text)         \n",
        "  \n",
        "  #remove links\n",
        "  text = re.sub(r'http\\S+', '', text)  \n",
        "  \n",
        "  #split token to remove extra spaces\n",
        "  tokens = text.split()\n",
        "  \n",
        "  #join tokens by space\n",
        "  return \" \".join(tokens)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykLsz50lCnXC"
      },
      "source": [
        "# perform text cleaning\n",
        "train_df['clean_text']= train_df['tweet'].apply(preprocessor)\n",
        "test_df['clean_text']= test_df['tweet'].apply(preprocessor)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEnvlwJdz9-t"
      },
      "source": [
        "# save cleaned text and labels to a variable\n",
        "text   = train_df['clean_text'].values\n",
        "labels = train_df['label'].values\n",
        "\n",
        "test_text = test_df['clean_text'].values"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7qq7aLst01a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56b55ca8-d690-4a52-d4a5-b359ecad4645"
      },
      "source": [
        "#cleaned text\n",
        "text[50:55]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['would my new \"talking antoine\" #iphone app! check it out now! #106 in the us ent #appstore …',\n",
              "       'all at once #joy #peace #reflect #remember #sky #cloud #cloudhub #skyhub #tree #gr$&@*# #iphone…',\n",
              "       'love you baby boy #baby #boy #babyboy #muesli #hedgehog #pet him #iphone #iphone7…',\n",
              "       'inbox: letters to the editor #news #photography #fashion #health #fail #tech #ipad #iphone #funny #lolpic.twitter.com/ik1rhumovz',\n",
              "       'thinner faster amazing, i hated ipad and will be getting one so ye…'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnbVmXPN_ao6"
      },
      "source": [
        "##3.3 Preparing Input and Output Data\n",
        "\n",
        "\n",
        "**Preparing Output**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqzd8-2P0l3T"
      },
      "source": [
        "#importing label encoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#define label encoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "#fit and transform target strings to a numbers\n",
        "labels = le.fit_transform(labels)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhOF8XUDWuHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a73dcf-0c77-4cc5-a6c8-35d7a4f67874"
      },
      "source": [
        "#classes\n",
        "le.classes_"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBFVkRgoDX_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40cc81f1-d3bf-4df0-e1ca-bdadf325d852"
      },
      "source": [
        "labels"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKh8Rcuw_vOt"
      },
      "source": [
        "**Preparing Input Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eUFCQkM0-Nf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "8a750566-ff43-4259-f0e8-66d55385237e"
      },
      "source": [
        "# library for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# compute no. of words in each tweet\n",
        "num = [len(i.split()) for i in text]\n",
        "\n",
        "plt.hist(num, bins = 30)\n",
        "\n",
        "plt.title(\"Histogram: Length of sentences\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Histogram: Length of sentences')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0bMmY6M0-Zs"
      },
      "source": [
        "# define maximum length of a text\n",
        "max_len = 35"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXbV1OazzSnr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "c1e0542296cf427da9ddeb86768ee6db",
            "3802615fd91e4ecca1ec179daa5c70b3",
            "1afbb7aa25a2483c8209c4313d370f11",
            "89ca3ca3236b440782ec8cce8a632e50",
            "402e40ba01ad4dd5907e07e876d1e0e0",
            "0c58dd0134c748dc9c9799d745c61477",
            "7637bb424b3e47e7871437089c2c9eb4",
            "c7ed2ff1a3084b72ba86d58b30c8004a",
            "87b98438c4e44383a557509a49ba4f58",
            "334e4067aa124dffb62b58f38fac7554",
            "95aed824f4ff4e9a924ec050b406294b",
            "761c21001fed463ab548f9d2efa4b2ee",
            "3b1ab31f05fb4988a4618c935750b381",
            "c497c19528d84eecbfab9f608e5c033d",
            "ac5ea4af023b486a92cbeed2cc6f6878",
            "b3f1c6a54a544104ac92ab144e77ba17",
            "09ee52d6e59a47a9841d8aaf23ffcffd",
            "319d849a295f4e7f9160361d4bf29e85",
            "35882b3befee48aaad2a3f70c36d5d55",
            "31a4bd5d7e124c0a8778fee96b3db5ef",
            "cd0a813cc5ca47459df6889aed11729f",
            "e012a26451654d2d993d5515bd5569ac"
          ]
        },
        "outputId": "30de22b8-6d6b-4fce-b10d-d27d1984b53b"
      },
      "source": [
        "# library for progress bar\n",
        "from tqdm import notebook\n",
        "\n",
        "# create an empty list to save integer sequence\n",
        "sent_id = []\n",
        "\n",
        "# iterate over each tweet\n",
        "for i in notebook.tqdm(range(len(text))):\n",
        "  \n",
        "  encoded_sent = tokenizer.encode(text[i],                      \n",
        "                                  add_special_tokens = True,    \n",
        "                                  max_length = max_len,\n",
        "                                  truncation = True,         \n",
        "                                  pad_to_max_length='right')    \n",
        "  \n",
        "  # saving integer sequence to a list\n",
        "  sent_id.append(encoded_sent)\n",
        "\n",
        "#\n",
        "# create an empty list to save integer sequence\n",
        "test_sent_id = []\n",
        "\n",
        "# iterate over each tweet\n",
        "for i in notebook.tqdm(range(len(test_text))):\n",
        "  \n",
        "  encoded_sent = tokenizer.encode(test_text[i],                      \n",
        "                                  add_special_tokens = True,    \n",
        "                                  max_length = max_len,\n",
        "                                  truncation = True,         \n",
        "                                  pad_to_max_length='right')    \n",
        "  \n",
        "  # saving integer sequence to a list\n",
        "  test_sent_id.append(encoded_sent)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1e0542296cf427da9ddeb86768ee6db",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7920 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "761c21001fed463ab548f9d2efa4b2ee",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1953 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVgp93PgwLg7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d11570dc-f24d-4a79-90aa-e15fccb33746"
      },
      "source": [
        "print(\"Integer Sequence:\",sent_id[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Integer Sequence: [101, 1001, 4344, 16550, 1001, 10032, 3231, 1001, 11924, 1001, 18726, 1001, 3376, 1001, 10140, 1001, 2740, 1001, 1045, 15776, 1001, 18059, 2239, 2135, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k73WKt0NxpeC"
      },
      "source": [
        "# create attention masks\n",
        "attention_masks = []\n",
        "test_attention_masks = []\n",
        "\n",
        "# for each sentence...\n",
        "for sent in sent_id:\n",
        "  att_mask = [int(token_id > 0) for token_id in sent]\n",
        "  \n",
        "  # store the attention mask for this sentence.\n",
        "  attention_masks.append(att_mask)\n",
        "\n",
        "for sent in test_sent_id:\n",
        "  att_mask = [int(token_id > 0) for token_id in sent]\n",
        "  \n",
        "  # store the attention mask for this sentence.\n",
        "  test_attention_masks.append(att_mask)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YONLj9J9AXQN"
      },
      "source": [
        "##3.4 Training and Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqg2GTsqxpuW"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(sent_id, labels, random_state=2018, test_size=0.1, stratify=labels)\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=2018, test_size=0.1, stratify=labels)\n",
        "\n",
        "#For test\n",
        "test_inputs = test_sent_id\n",
        "test_masks = test_attention_masks"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y42CmxNaAsbZ"
      },
      "source": [
        "##3.5 Define Dataloaders\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "033DKuEizSuP"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "test_inputs = torch.tensor(test_inputs)\n",
        "test_masks = torch.tensor(test_masks)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40Op_QSrUvem",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "7c6737c8-05d0-4585-819b-3720809addda"
      },
      "source": [
        "# understand the class distribution\n",
        "keys=['0','1']\n",
        "\n",
        "# set figure size\n",
        "plt.figure(figsize=(5,5))\n",
        "\n",
        "# plot bat chart\n",
        "plt.bar(keys,class_counts)\n",
        "\n",
        "# set title\n",
        "plt.title('Class Distribution')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Class Distribution')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpluCEUzijp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b6884a-1ab1-4c17-9335-d4b58e120400"
      },
      "source": [
        "#library for array processing\n",
        "import numpy as np\n",
        "\n",
        "#library for computing class weights\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_weights = compute_class_weight('balanced', np.unique(labels), labels)\n",
        "weights= torch.tensor(class_weights,dtype=torch.float)\n",
        "\n",
        "print(\"Class Weights:\",class_weights)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: [0.6718697  1.95459033]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPnDd5SCzWS6"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "#Dataset wrapping tensors.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "\n",
        "#define a sampler for sampling the data during training\n",
        "  #random sampler samples randomly from a dataset \n",
        "  #sequential sampler samples sequentially, always in the same order\n",
        "#train_sampler = RandomSampler(train_data)\n",
        "\n",
        "train_samples_weight = [class_weights[class_id] for class_id in train_labels]\n",
        "validation_samples_weight = [class_weights[class_id] for class_id in validation_labels]\n",
        "\n",
        "train_sampler = WeightedRandomSampler(train_samples_weight, len(train_samples_weight), replacement=True)\n",
        "\n",
        "#represents a iterator over a dataset. Supports batching, customized data loading order\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "#Dataset wrapping tensors.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "\n",
        "#define a sequential sampler \n",
        "#This samples data in a sequential order\n",
        "#validation_sampler = SequentialSampler(validation_data)\n",
        "validation_sampler = WeightedRandomSampler(validation_samples_weight, len(validation_samples_weight), replacement=True)\n",
        "\n",
        "#create a iterator over the dataset\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "#creating DataLoader for the test set\n",
        "test_data = TensorDataset(test_inputs, test_masks)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9_8jhY8pmPf"
      },
      "source": [
        "temp = 0\n",
        "print(len(train_dataloader), len(train_data))\n",
        "for step,batch in enumerate(train_dataloader):\n",
        "    if temp > 10:\n",
        "      break\n",
        "    sent_id, mask, labels = batch\n",
        "    print( step, len(labels), sum(labels)/ len(labels))\n",
        "    temp = temp + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGFO9vX1WD5-"
      },
      "source": [
        "#create an iterator object\n",
        "iterator = iter(train_dataloader)\n",
        "\n",
        "#loads batch data\n",
        "sent_id, mask, target=iterator.next()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek5ie3hqF7Fk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e39048dd-f923-4049-b78b-d334f46fc880"
      },
      "source": [
        "sent_id.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELWRXJV0F1vm"
      },
      "source": [
        "sent_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ88suqBjeuo"
      },
      "source": [
        "#pass inputs to the model\n",
        "outputs = bert(sent_id,             #integer sequence\n",
        "               attention_mask=mask, \n",
        "                return_dict=False) #attention masks"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WleBnOAn5V7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73e0696a-b828-4382-f57d-1e4721a25e6f"
      },
      "source": [
        "# hidden states\n",
        "hidden_states = outputs[0]\n",
        "\n",
        "# [CLS] hidden state\n",
        "CLS_hidden_state = outputs[1]\n",
        "\n",
        "print(\"Shape of Hidden States:\",hidden_states.shape)\n",
        "print(\"Shape of CLS Hidden State:\",CLS_hidden_state.shape)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Hidden States: torch.Size([32, 25, 768])\n",
            "Shape of CLS Hidden State: torch.Size([32, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4pyt_I-8ob9",
        "outputId": "28e22fc3-c1e4-4070-e35e-5c1423264869"
      },
      "source": [
        "#create an iterator object\n",
        "test_iterator = iter(test_dataloader)\n",
        "\n",
        "#loads batch data\n",
        "test_sent_id, test_mask=test_iterator.next()\n",
        "test_sent_id.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 25])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb189wFSR0cE"
      },
      "source": [
        "#4. Model Finetuning \n",
        "\n",
        "*The pretrained model is trained on the general domain corpus. So, finetuning the pretrained model helps in the capturing the domain specific features from our custom dataset*\n",
        "\n",
        "\n",
        "Every pretrained model is trained using 2 different layers : **BackBone and Head** \n",
        "\n",
        "* Backbone refers to the pretrained model architecture \n",
        "* Head refers to the dense layer added on top of backbone. Generally, this layer is used for the classification tasks.\n",
        "\n",
        "Hence, we can finetune the pretrained model in 2 ways\n",
        "\n",
        "**1. Fine-Tuning only Head (or Dense Layer)**\n",
        "\n",
        "1.1  CLS token\n",
        "\n",
        "1.2  Hidden states\n",
        "\n",
        "\n",
        "**2. Fine-Tuning both Backbone & Head**\n",
        "\n",
        "1.1  CLS token\n",
        "\n",
        "1.2  Hidden states \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml6av5LqA24e"
      },
      "source": [
        "### 4.1 Approach: Fine-Tuning Only Head\n",
        "\n",
        "As the name suggests, in this approach, we freeze the backbone and train only the head or dense layer.\n",
        "\n",
        "### Steps to Follow\n",
        "\n",
        "1. Turn off Gradients\n",
        "\n",
        "2. Define Model Architecture\n",
        "\n",
        "3. Define Optimizer and Loss\n",
        "\n",
        "4. Define Train and Evaluate\n",
        "\n",
        "5. Train the model\n",
        "\n",
        "6. Evaluate the model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDpxm52C5mpe"
      },
      "source": [
        "# turn off the gradient of all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kF7mh9TM_Rl"
      },
      "source": [
        "##4.2 Define Model Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RIDAa4NF5m5"
      },
      "source": [
        "#importing nn module\n",
        "import torch.nn as nn\n",
        "\n",
        "class classifier(nn.Module):\n",
        "\n",
        "    #define the layers and wrappers used by model\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      #constructor\n",
        "      super(classifier, self).__init__()\n",
        "\n",
        "      #bert model\n",
        "      self.bert = bert \n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(1024,512)\n",
        "      \n",
        "      #dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,1)\n",
        "      \n",
        "      #dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "      #relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      #softmax activation function\n",
        "      #self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "      #Sigmoid for binary classification\n",
        "      self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      all_hidden_states, cls_hidden_state = self.bert(sent_id, attention_mask=mask,  return_dict=False)\n",
        "      \n",
        "      #pass CLS hidden state to dense layer\n",
        "      x = self.fc1(cls_hidden_state)\n",
        "\n",
        "      #Apply ReLU activation function\n",
        "      x = self.relu(x)\n",
        "\n",
        "      #Apply Dropout\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      #pass input to the output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      #apply sigmoid activation\n",
        "      x = self.sigmoid(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb6z3HDPF5lA"
      },
      "source": [
        "#create the model\n",
        "model = classifier(bert)\n",
        "\n",
        "#push the model to GPU, if available\n",
        "#model = model.to(device)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9R5XajGF5jA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a2d90f-07d4-4eed-f52d-cde450924d2d"
      },
      "source": [
        "#model architecture \n",
        "model"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "classifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (relu): ReLU()\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fxTyKbRUGC5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "3dfcb8e2-c817-4606-e551-27ec51124ee4"
      },
      "source": [
        "# push the tensors to GPU\n",
        "'''sent_id = sent_id.to(device)\n",
        "mask = mask.to(device)\n",
        "target = target.to(device)'''\n",
        "\n",
        "# pass inputs to the model\n",
        "outputs = model(sent_id, mask)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-17c3bc608f7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# pass inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-011615c4261f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m       \u001b[0;31m#pass the inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m       \u001b[0mall_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_hidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0;31m#pass CLS hidden state to dense layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLwIPXWNWg4I"
      },
      "source": [
        "# understand outputs\n",
        "print(outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFJoc1aGYN1P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38121508-48cc-446c-c456-b38d52d52a74"
      },
      "source": [
        "# no. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 394,241 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOTdl4RZNHk4"
      },
      "source": [
        "## 4.3 Define Optimizer and Loss function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny7fjPGyQaVw"
      },
      "source": [
        "# Adam optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsJuWGiqF5eM"
      },
      "source": [
        "# converting a list of class weights to a tensor\n",
        "#weights= torch.tensor(class_weights,dtype=torch.float)\n",
        "\n",
        "# transfer to GPU\n",
        "#weights = weights.to(device)\n",
        "\n",
        "# define the loss function\n",
        "#cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "cross_entropy  = nn.BCELoss() #nn.NLLLoss() \n",
        "#cross_entropy  = nn.BCEWithLogitsLoss(weight=weights)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiSVYYWGkCLK",
        "outputId": "2cded2b2-241b-4f04-e5c3-859f0987f245"
      },
      "source": [
        "print(outputs.shape, target.reshape(-1,1).shape)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1]) torch.Size([32, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqtirPVDg8aA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "578da4ba-71c7-4eed-877c-b63f51354b15"
      },
      "source": [
        "#compute the loss\n",
        "loss = cross_entropy(outputs, target.float().reshape(-1,1))\n",
        "print(\"Loss:\",loss)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-9fb86cf6effd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#compute the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-Sx2rgyu4Aj"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "# compute time in hh:mm:ss\n",
        "def format_time(elapsed):\n",
        "    # round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds = elapsed_rounded))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJixsg1XzHCA"
      },
      "source": [
        "## 4.4 Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFPILeF9Spxe"
      },
      "source": [
        "The deep learning model is trained in the form of epochs where in each epoch consists of several batches.\n",
        "\n",
        "During training, for each batch, we need to\n",
        "\n",
        "1. Perform Forward Pass\n",
        "2. Compute Loss\n",
        "3. Backpropagate Loss\n",
        "4. Update Weights \n",
        "\n",
        "Where as during evaluation, for each batch, we need to\n",
        "\n",
        "1. Perform forward pass\n",
        "2. Compute loss\n",
        "\n",
        "```\n",
        "Training: Epoch -> Batch -> Forward Pass -> Compute loss -> Backpropagate loss -> Update weights \n",
        "```\n",
        "\n",
        "```\n",
        "Evaluation: Epoch -> Batch -> Forward Pass -> Compute loss\n",
        "```\n",
        "\n",
        "Hence, for each epoch, we have a training phase and a validation phase. After each batch we need to:\n",
        "\n",
        "**Training phase**\n",
        "\n",
        "1. Load data onto the GPU for acceleration\n",
        "\n",
        "2. Unpack our data inputs and labels\n",
        "\n",
        "3. Clear out the gradients calculated in the previous pass.\n",
        "\n",
        "4. Forward pass (feed input data through the network)\n",
        "\n",
        "5. Backward pass (backpropagation)\n",
        "\n",
        "6. Update parameters with optimizer.step()\n",
        "\n",
        "7. Track variables for monitoring progress\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgIYKxjv2Wv0"
      },
      "source": [
        "#define a function for training the model\n",
        "def train():\n",
        "  \n",
        "  print(\"\\nTraining.....\")  \n",
        "  \n",
        "  #set the model on training phase - Dropout layers are activated\n",
        "  model.train()\n",
        "\n",
        "  #record the current time\n",
        "  t0 = time.time()\n",
        "\n",
        "  #initialize loss and accuracy to 0\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  #Create a empty list to save the model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  #for every batch\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # Progress update after every 40 batches.\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "    #push the batch to gpu\n",
        "    #batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    #unpack the batch into separate variables\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # Always clear any previously calculated gradients before performing a\n",
        "    # backward pass. PyTorch doesn't do this automatically. \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # Perform a forward pass. This returns the model predictions\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    #compute the loss between actual and predicted values\n",
        "    loss =  cross_entropy(preds, labels.float().unsqueeze(-1))\n",
        "\n",
        "    # Accumulate the training loss over all of the batches so that we can\n",
        "    # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "    # single value; the `.item()` function just returns the Python value \n",
        "    # from the tensor.\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # Perform a backward pass to calculate the gradients.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters and take a step using the computed gradient.\n",
        "    # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "    # modified based on their gradients, the learning rate, etc.\n",
        "    optimizer.step()\n",
        "\n",
        "    #The model predictions are stored on GPU. So, push it to CPU\n",
        "    #preds=preds.detach().cpu().numpy()\n",
        "    preds=preds.detach().numpy()\n",
        "\n",
        "    #Accumulate the model predictions of each batch\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  #compute the training loss of a epoch\n",
        "  avg_loss     = total_loss / len(train_dataloader)\n",
        "  \n",
        "  #The predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  #So, reshaping the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SF3wrDuSwpj"
      },
      "source": [
        "\n",
        "**Evaluation phase**\n",
        "\n",
        "1. Load data onto the GPU for acceleration\n",
        "\n",
        "2. Unpack our data inputs and labels\n",
        "\n",
        "3. Forward pass (feed input data through the network)\n",
        "\n",
        "4. Compute loss on our validation data\n",
        "\n",
        "5. Track variables for monitoring progress\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPKfeGlC5_WE"
      },
      "source": [
        "#define a function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating.....\")\n",
        "  \n",
        "  #set the model on training phase - Dropout layers are deactivated\n",
        "  model.eval()\n",
        "\n",
        "  #record the current time\n",
        "  t0 = time.time()\n",
        "\n",
        "  #initialize the loss and accuracy to 0\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  #Create a empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  #for each batch  \n",
        "  for step,batch in enumerate(validation_dataloader):\n",
        "    \n",
        "    # Progress update every 40 batches.\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(validation_dataloader), elapsed))\n",
        "\n",
        "    #push the batch to gpu\n",
        "    #batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    #unpack the batch into separate variables\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels        \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # Perform a forward pass. This returns the model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      #compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels.float().unsqueeze(-1))\n",
        "\n",
        "      # Accumulate the validation loss over all of the batches so that we can\n",
        "      # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "      # single value; the `.item()` function just returns the Python value \n",
        "      # from the tensor.      \n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      #The model predictions are stored on GPU. So, push it to CPU\n",
        "      #preds=preds.detach().cpu().numpy()\n",
        "      preds=preds.detach().numpy()\n",
        "\n",
        "      #Accumulate the model predictions of each batch\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  #compute the validation loss of a epoch\n",
        "  avg_loss = total_loss / len(validation_dataloader) \n",
        "\n",
        "  #The predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  #So, reshaping the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKNi1sZI7Dgy"
      },
      "source": [
        "#define a function for evaluating the model\n",
        "def predict():\n",
        "  \n",
        "  print(\"\\nPredicting.....\")\n",
        "  \n",
        "  #set the model on training phase - Dropout layers are deactivated\n",
        "  #model.eval()\n",
        "\n",
        "  #record the current time\n",
        "  t0 = time.time()\n",
        "  \n",
        "  #Create a empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  #for each batch  \n",
        "  for step,batch in enumerate(test_dataloader):\n",
        "    \n",
        "    # Progress update every 40 batches.\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    #push the batch to gpu\n",
        "    #batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    #unpack the batch into separate variables\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels        \n",
        "    sent_id, mask = batch\n",
        "\n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # Perform a forward pass. This returns the model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      #The model predictions are stored on GPU. So, push it to CPU\n",
        "      #preds=preds.detach().cpu().numpy()\n",
        "      preds=preds.detach().numpy()\n",
        "\n",
        "      #Accumulate the model predictions of each batch\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  #The predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  #So, reshaping the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return total_preds"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7d_XacvNgyU"
      },
      "source": [
        "##4.5 Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_sj66daFTAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e636c115-6e80-47ab-8c26-838c6565e417"
      },
      "source": [
        "import os\n",
        "best_model_path = os.path.join(dataDir, 'saved_weights.pt')\n",
        "\n",
        "#Assign the initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "#create a empty list to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n....... epoch {:} / {:} .......'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "    \n",
        "    #accumulate training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "....... epoch 1 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:47.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:33.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:19.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:05.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:51.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.610\n",
            "Validation Loss: 0.579\n",
            "\n",
            "....... epoch 2 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:51.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:37.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:23.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:09.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:55.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.542\n",
            "Validation Loss: 0.458\n",
            "\n",
            "....... epoch 3 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:51.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:37.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:23.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:09.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:55.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.500\n",
            "Validation Loss: 0.547\n",
            "\n",
            "....... epoch 4 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:47.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:33.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:20.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:06.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:53.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.494\n",
            "Validation Loss: 0.488\n",
            "\n",
            "....... epoch 5 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:46.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:32.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:18.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:05.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:51.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.472\n",
            "Validation Loss: 0.385\n",
            "\n",
            "....... epoch 6 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:49.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:35.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:21.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:07.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:52.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.449\n",
            "Validation Loss: 0.385\n",
            "\n",
            "....... epoch 7 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:46.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:31.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:16.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:01.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:47.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.430\n",
            "Validation Loss: 0.370\n",
            "\n",
            "....... epoch 8 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:49.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:34.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:21.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:07.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:53.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.440\n",
            "Validation Loss: 0.389\n",
            "\n",
            "....... epoch 9 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:46.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:33.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:19.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:12.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:58.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.423\n",
            "Validation Loss: 0.385\n",
            "\n",
            "....... epoch 10 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:46.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:33.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:19.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:06.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:54.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.445\n",
            "Validation Loss: 0.506\n",
            "\n",
            "....... epoch 11 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:46.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:33.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:19.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:06.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:52.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.439\n",
            "Validation Loss: 0.442\n",
            "\n",
            "....... epoch 12 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:46.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:32.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:18.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:04.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:50.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.431\n",
            "Validation Loss: 0.382\n",
            "\n",
            "....... epoch 13 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:46.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:32.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:17.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:02.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:48.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.407\n",
            "Validation Loss: 0.403\n",
            "\n",
            "....... epoch 14 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:45.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:31.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:16.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:03.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:49.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.405\n",
            "Validation Loss: 0.345\n",
            "\n",
            "....... epoch 15 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:55.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:41.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:27.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:13.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:58.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.424\n",
            "Validation Loss: 0.360\n",
            "\n",
            "....... epoch 16 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:46.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:32.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:18.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:04.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:50.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.419\n",
            "Validation Loss: 0.408\n",
            "\n",
            "....... epoch 17 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:47.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:34.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:23.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:09.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:56.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.418\n",
            "Validation Loss: 0.350\n",
            "\n",
            "....... epoch 18 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:46.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:32.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:18.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:04.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:50.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.423\n",
            "Validation Loss: 0.429\n",
            "\n",
            "....... epoch 19 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:46.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:32.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:18.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:03.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:49.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.407\n",
            "Validation Loss: 0.465\n",
            "\n",
            "....... epoch 20 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    223.    Elapsed: 0:02:46.\n",
            "  Batch    80  of    223.    Elapsed: 0:05:33.\n",
            "  Batch   120  of    223.    Elapsed: 0:08:19.\n",
            "  Batch   160  of    223.    Elapsed: 0:11:05.\n",
            "  Batch   200  of    223.    Elapsed: 0:13:51.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.402\n",
            "Validation Loss: 0.401\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNhFJ0DANldu"
      },
      "source": [
        "##4.6 Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4OPuAKj6Kiw"
      },
      "source": [
        "import os\n",
        "# load weights of best model\n",
        "path='saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "best_model_path = os.path.join(dataDir, 'saved_weights.pt')\n",
        "torch.save(model.state_dict(), best_model_path)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOhE44CsxZnD",
        "outputId": "3a9b2a31-9611-488a-aed9-cbf8d95574cb"
      },
      "source": [
        "import os\n",
        "best_model_path = os.path.join(dataDir, 'saved_weights.pt')\n",
        "model.load_state_dict(torch.load(best_model_path))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coqwKsGeFTDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e85e48a-62e5-4da5-fdb3-e5d0d8aad5b8"
      },
      "source": [
        "# get the model predictions on the validation data\n",
        "# returns 2 elements- Validation loss and Predictions\n",
        "valid_loss, preds = evaluate()\n",
        "print(valid_loss)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating.....\n",
            "0.36329843521118166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bBO4oo49B3W",
        "outputId": "d56e02d3-4cb8-4e1c-d1b5-cd27323f5513"
      },
      "source": [
        "test_preds = predict()\n",
        "THRESHOLD = 0.5\n",
        "y_test_pred = test_preds.copy()\n",
        "y_test_pred[y_test_pred > THRESHOLD] = 1\n",
        "y_test_pred [ y_test_pred <= THRESHOLD] = 0\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicting.....\n",
            "  Batch    40  of     62.    Elapsed: 0:02:39.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-x4pSaR9yeX"
      },
      "source": [
        "test_df_submit = test_df.copy()\n",
        "test_df_submit['label'] = y_test_pred\n",
        "test_df_submit[['id', 'label']].to_csv(os.path.join(dataDir, 'submission 5 bert-large model.csv'), index = False)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DehF35geFTIB"
      },
      "source": [
        "# Converting the log(probabities) into a classes\n",
        "# Choosing index of a maximum value as class\n",
        "#y_pred = np.argmax(preds,axis=1)\n",
        "\n",
        "THRESHOLD = 0.5\n",
        "y_pred = preds.copy()\n",
        "y_pred[y_pred > THRESHOLD] = 1\n",
        "y_pred [ y_pred <= THRESHOLD] = 0\n",
        "\n",
        "\n",
        "# actual labels\n",
        "y_true = validation_labels"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXjiXdk5Co8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5af41f7-6c1b-48b7-eff8-13c4cda02bd8"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true,y_pred))"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.51      0.60       589\n",
            "           1       0.24      0.45      0.31       203\n",
            "\n",
            "    accuracy                           0.49       792\n",
            "   macro avg       0.48      0.48      0.45       792\n",
            "weighted avg       0.60      0.49      0.52       792\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJL4-gz7-E17"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}