{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                id        label\n",
      "count  7920.000000  7920.000000\n",
      "mean   3960.500000     0.255808\n",
      "std    2286.451399     0.436342\n",
      "min       1.000000     0.000000\n",
      "25%    1980.750000     0.000000\n",
      "50%    3960.500000     0.000000\n",
      "75%    5940.250000     1.000000\n",
      "max    7920.000000     1.000000\n",
      "                id\n",
      "count  1953.000000\n",
      "mean   8897.000000\n",
      "std     563.926857\n",
      "min    7921.000000\n",
      "25%    8409.000000\n",
      "50%    8897.000000\n",
      "75%    9385.000000\n",
      "max    9873.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('vader_lexicon')\n",
    "import re\n",
    "import string\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import emoji\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "TRAIN_PATH = 'C:\\\\AI Learning\\\\Analytics Vidhya\\\\Twitter Sentiment'\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(TRAIN_PATH,\"train_2kmZucJ.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(TRAIN_PATH,\"test_oJQbWVk.csv\"))\n",
    "\n",
    "#train_data.hist(bins=50, figsize=(20,15))\n",
    "#train_data.drop(['id', 'lang', 'original_author','retweet_count'], axis=1, inplace=True)\n",
    "#test_data.drop(['id', 'lang', 'original_author','retweet_count'], axis=1, inplace=True)\n",
    "print(train_data.describe())\n",
    "print(test_data.describe())\n",
    "#ps = nltk.PorterStemmer()\n",
    "#new_text = \"I would really like to have a black color Ather with red coloured rim (rather than yellow) for collectors edition ! Would be really damn nice with that find and roses theme \" #train_data[\"original_text\"][11]\n",
    "#new_text = re.sub(r'\\W+', ' ', new_text, flags=re.M)\n",
    "#words = word_tokenize(new_text)\n",
    "#for w in words:\n",
    "#    print(ps.stem(w))\n",
    "#tokens = word_tokenize(new_text)\n",
    "#tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# remove all tokens that are not alphabetic\n",
    "#words = [word for word in tokens if word.isalpha()]\n",
    "\n",
    "#stop_words = set(stopwords.words('english'))\n",
    "#words = [w for w in words if not w in stop_words]\n",
    "#words = [ps.stem(w) for w in words]\n",
    "#print(words[:100])\n",
    "\n",
    "#sid = SentimentIntensityAnalyzer()\n",
    "#scores = sid.polarity_scores(new_text)\n",
    "\n",
    "#print(scores)\n",
    "#for key in sorted(scores):\n",
    "#        print('{0}: {1}, '.format(key, scores[key]), end='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCounts(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def count_regex(self, pattern, tweet):\n",
    "        return len(re.findall(pattern, tweet))\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        # fit method is used when specific operations need to be done on the train data, but not on the test data\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        count_words = []\n",
    "        count_mentions = []\n",
    "        count_hashtags = []\n",
    "        count_capital_words = []\n",
    "        count_excl_quest_marks = []\n",
    "        count_urls = []\n",
    "        # We will replace the emoji symbols with a description, which makes using a regex for counting easier\n",
    "        # Moreover, it will result in having more words in the tweet\n",
    "        count_emojis = []\n",
    "        #print(X.head())\n",
    "        for x in X:\n",
    "            count_words.append(self.count_regex(r'\\w+', x))\n",
    "            count_mentions.append(self.count_regex(r'@\\w+', x))\n",
    "            count_hashtags.append(self.count_regex(r'#\\w+', x))\n",
    "            count_capital_words.append(self.count_regex(r'\\b[A-Z]{2,}\\b', x))\n",
    "            count_excl_quest_marks.append(self.count_regex(r'!|\\?', x))\n",
    "            count_urls.append(self.count_regex(r'http.?://[^\\s]+[\\s]?', x))\n",
    "            # We will replace the emoji symbols with a description, which makes using a regex for counting easier\n",
    "            # Moreover, it will result in having more words in the tweet\n",
    "            count_emojis.append(self.count_regex(r':[a-z_&]+:', emoji.demojize(x)))\n",
    "        \n",
    "#        count_words = X.apply(lambda x: self.count_regex(r'\\w+', x)) \n",
    "#        count_mentions = X.apply(lambda x: self.count_regex(r'@\\w+', x))\n",
    "#        count_hashtags = X.apply(lambda x: self.count_regex(r'#\\w+', x))\n",
    "#        count_capital_words = X.apply(lambda x: self.count_regex(r'\\b[A-Z]{2,}\\b', x))\n",
    "#        count_excl_quest_marks = X.apply(lambda x: self.count_regex(r'!|\\?', x))\n",
    "#        count_urls = X.apply(lambda x: self.count_regex(r'http.?://[^\\s]+[\\s]?', x))\n",
    "        # We will replace the emoji symbols with a description, which makes using a regex for counting easier\n",
    "        # Moreover, it will result in having more words in the tweet\n",
    "#        count_emojis = X.apply(lambda x: emoji.demojize(x)).apply(lambda x: self.count_regex(r':[a-z_&]+:', x))\n",
    "        \n",
    "        df = pd.DataFrame({'count_words': count_words\n",
    "                           , 'count_mentions': count_mentions\n",
    "                           , 'count_hashtags': count_hashtags\n",
    "                           , 'count_capital_words': count_capital_words\n",
    "                           , 'count_excl_quest_marks': count_excl_quest_marks\n",
    "                           , 'count_urls': count_urls\n",
    "                           , 'count_emojis': count_emojis\n",
    "                          })\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanText(BaseEstimator, TransformerMixin):\n",
    "    def remove_mentions(self, input_text):\n",
    "        return re.sub(r'@\\w+', '', input_text)\n",
    "    \n",
    "    def remove_urls(self, input_text):\n",
    "        return re.sub(r'http.?://[^\\s]+[\\s]?', '', input_text)\n",
    "    \n",
    "    def emoji_oneword(self, input_text):\n",
    "        # By compressing the underscore, the emoji is kept as one word\n",
    "        return input_text.replace('_','')\n",
    "    \n",
    "    def remove_punctuation(self, input_text):\n",
    "        # Make translation table\n",
    "        punct = string.punctuation\n",
    "        trantab = str.maketrans(punct, len(punct)*' ')  # Every punctuation symbol will be replaced by a space\n",
    "        return input_text.translate(trantab)\n",
    "    \n",
    "    def remove_digits(self, input_text):\n",
    "        return re.sub('\\d+', '', input_text)\n",
    "    \n",
    "    def to_lower(self, input_text):\n",
    "        return input_text.lower()\n",
    "    \n",
    "    def remove_stopwords(self, input_text):\n",
    "        stopwords_list = stopwords.words('english')\n",
    "        # Some words which might indicate a certain sentiment are kept via a whitelist\n",
    "        whitelist = [\"n't\", \"not\", \"no\"]\n",
    "        words = input_text.split() \n",
    "        clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
    "        return \" \".join(clean_words) \n",
    "    \n",
    "    def stemming(self, input_text):\n",
    "        porter = nltk.PorterStemmer()\n",
    "        words = input_text.split() \n",
    "        stemmed_words = [porter.stem(word) for word in words]\n",
    "        return \" \".join(stemmed_words)\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        clean_X = []\n",
    "        for x in X:\n",
    "            x = re.sub(r'@\\w+', '', x) #remove_mentions\n",
    "            x = re.sub(r'http.?://[^\\s]+[\\s]?', '', x) #remove_urls\n",
    "            x = x.replace('_','') #emoji_oneword\n",
    "            \n",
    "            # Every punctuation symbol will be replaced by a space\n",
    "            punct = string.punctuation\n",
    "            trantab = str.maketrans(punct, len(punct)*' ')  \n",
    "            x = x.translate(trantab)\n",
    "            \n",
    "            x = re.sub('\\d+', '', x) #remove_digits\n",
    "            \n",
    "            x = x.lower() #to_lower\n",
    "            \n",
    "            #remove_stopwords\n",
    "            stopwords_list = stopwords.words('english')\n",
    "            whitelist = [\"n't\", \"not\", \"no\"]\n",
    "            words = x.split() \n",
    "            clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
    "            x = \" \".join(clean_words) \n",
    "            \n",
    "            #Stem\n",
    "            porter = nltk.PorterStemmer()\n",
    "            words = x.split() \n",
    "            stemmed_words = [porter.stem(word) for word in words]\n",
    "            x = \" \".join(stemmed_words)\n",
    "            \n",
    "            clean_X.append(x)\n",
    "        #clean_X = X.apply(self.remove_mentions).apply(self.remove_urls).apply(self.remove_punctuation).apply(self.emoji_oneword).apply(self.remove_digits).apply(self.to_lower).apply(self.remove_stopwords).apply(self.stemming)\n",
    "        return np.array(clean_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = TextCounts()\n",
    "train_data_eda = tc.fit_transform(train_data.original_text)\n",
    "train_data_eda['sentiment_class'] = train_data.sentiment_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive stats for count_hashtags\n",
      "------------------------------------\n",
      "                  count      mean       std  min  25%  50%  75%   max\n",
      "sentiment_class                                                      \n",
      "-1                769.0  2.286086  2.967941  0.0  0.0  1.0  4.0  21.0\n",
      " 0               1701.0  2.407407  3.090466  0.0  0.0  1.0  3.0  28.0\n",
      " 1                765.0  2.287582  3.092960  0.0  0.0  1.0  3.0  27.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gandharv\\Anaconda3\\lib\\site-packages\\seaborn\\axisgrid.py:230: UserWarning: The `size` paramter has been renamed to `height`; please update your code.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "col = \"count_hashtags\"\n",
    "print('Descriptive stats for {}'.format(col))\n",
    "print('-'*(len(col)+22))\n",
    "print(train_data_eda.groupby('sentiment_class')[col].describe())\n",
    "bins = np.arange(train_data_eda[col].min(), train_data_eda[col].max() + 1)\n",
    "g = sns.FacetGrid(train_data_eda, col='sentiment_class', size=5, hue='sentiment_class', palette=\"PuBuGn_d\")\n",
    "g = g.map(sns.distplot, col, kde=False, norm_hist=True, bins=bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3235, 500)\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "ct = CleanText()\n",
    "train_data_clean = ct.fit_transform(train_data.original_text)\n",
    "\n",
    "hv = HashingVectorizer(n_features=500)\n",
    "bow = hv.transform(train_data_clean)\n",
    "print(bow.shape)\n",
    "#cv = CountVectorizer()\n",
    "#bow = cv.fit_transform(train_data_clean)\n",
    "#print(cv.vocabulary_)\n",
    "\n",
    "#word_freq = dict(zip(cv.get_feature_names(), np.asarray(bow.sum(axis=0)).ravel()))\n",
    "#word_counter = collections.Counter(word_freq)\n",
    "#word_counter_df = pd.DataFrame(word_counter.most_common(20), columns = ['word', 'freq'])\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(12, 10))\n",
    "#bar_freq_word = sns.barplot(x=\"word\", y=\"freq\", data=word_counter_df, palette=\"PuBuGn_d\", ax=ax)\n",
    "#plt.show();\n",
    "#if not KAGGLE_ENV: bar_freq_word.get_figure().savefig('../output/bar_freq_word.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['count_words',\n",
       " 'count_mentions',\n",
       " 'count_hashtags',\n",
       " 'count_capital_words',\n",
       " 'count_excl_quest_marks',\n",
       " 'count_urls',\n",
       " 'count_emojis',\n",
       " 'sentiment_class',\n",
       " 'clean_text']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_eda[\"clean_text\"] = train_data_clean\n",
    "train_data_eda.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7920\n",
      "1953\n",
      "9873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gandharv\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9873, 4103)\n",
      "(7920, 4103)\n"
     ]
    }
   ],
   "source": [
    "text_count_pipeline = Pipeline([\n",
    "    (\"textcounts\", TextCounts())\n",
    "])\n",
    "\n",
    "text_preprocess_pipeline = Pipeline([\n",
    "    (\"cleantext\", CleanText()),\n",
    "    (\"vect\", CountVectorizer(max_features=4096))\n",
    "])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"text_count_pipeline\", text_count_pipeline),\n",
    "        (\"text_preprocess_pipeline\", text_preprocess_pipeline),\n",
    "    ])\n",
    "\n",
    "train_rows = len(train_data[\"tweet\"])\n",
    "test_rows = len(test_data[\"tweet\"])\n",
    "\n",
    "print(train_rows)\n",
    "print(test_rows)\n",
    "combined = pd.concat([train_data, test_data], axis = 0)\n",
    "combined_rows = len(combined[\"tweet\"])\n",
    "\n",
    "print(combined_rows)\n",
    "\n",
    "#train_data_text = train_data.original_text\n",
    "\n",
    "train_data_labels = train_data.label\n",
    "combined_data_transformed = full_pipeline.fit_transform(combined.tweet)\n",
    "\n",
    "train_data_transformed = combined_data_transformed[0:train_rows]\n",
    "print(combined_data_transformed.shape)\n",
    "print(train_data_transformed.shape)\n",
    "#train_data_transformed[\"sentiment_class\"] = train_data[\"sentiment_class\"]\n",
    "#train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gandharv\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Gandharv\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.02, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_con...\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             iid='warn', n_jobs=5,\n",
       "             param_grid=[{'colsample_bytree': [0.6, 0.8, 1.0],\n",
       "                          'gamma': [0.5, 1, 1.5, 2, 5], 'max_depth': [3, 4, 5],\n",
       "                          'min_child_weight': [1, 5, 10],\n",
       "                          'subsample': [0.6, 0.8, 1.0]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_data_transformed, train_data_labels)\n",
    "\n",
    "xgb_model = XGBClassifier(learning_rate=0.02, n_estimators=600, objective=\"binary:logistic\", random_state=42)\n",
    "\n",
    "param_grid = [{\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }]\n",
    "\n",
    "\n",
    "clf = GridSearchCV(xgb_model, param_grid, n_jobs=5, scoring='f1')\n",
    "\n",
    "clf.fit(train_data_transformed, train_data_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9536974129743393\n",
      "0.916602404122653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(train_data_transformed)\n",
    "y_pred_xgb = clf.predict(train_data_transformed)\n",
    "\n",
    "print(f1_score(train_data_labels, y_pred, average = 'weighted'))\n",
    "print(f1_score(train_data_labels, y_pred_xgb, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_transformed = combined_data_transformed[train_rows:]\n",
    "#print(test_data_transformed.shape)\n",
    "test_data_pred = clf.predict(test_data_transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7921</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7922</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7926</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7927</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7928</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7929</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7930</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7931</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7935</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7936</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7937</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7940</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7942</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7943</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7944</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7945</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7948</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7950</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>9844</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>9845</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>9846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>9847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>9848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>9849</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>9850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>9851</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>9852</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>9853</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>9854</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>9855</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>9856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>9857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>9858</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>9859</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>9860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>9861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>9862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>9863</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>9864</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>9865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>9866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>9867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>9868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>9869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>9870</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>9871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>9872</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>9873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1953 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label\n",
       "0     7921      1\n",
       "1     7922      1\n",
       "2     7923      1\n",
       "3     7924      1\n",
       "4     7925      1\n",
       "5     7926      0\n",
       "6     7927      1\n",
       "7     7928      0\n",
       "8     7929      1\n",
       "9     7930      0\n",
       "10    7931      0\n",
       "11    7932      0\n",
       "12    7933      0\n",
       "13    7934      0\n",
       "14    7935      0\n",
       "15    7936      0\n",
       "16    7937      0\n",
       "17    7938      1\n",
       "18    7939      1\n",
       "19    7940      0\n",
       "20    7941      0\n",
       "21    7942      0\n",
       "22    7943      1\n",
       "23    7944      0\n",
       "24    7945      1\n",
       "25    7946      0\n",
       "26    7947      0\n",
       "27    7948      0\n",
       "28    7949      1\n",
       "29    7950      0\n",
       "...    ...    ...\n",
       "1923  9844      0\n",
       "1924  9845      0\n",
       "1925  9846      1\n",
       "1926  9847      0\n",
       "1927  9848      1\n",
       "1928  9849      0\n",
       "1929  9850      0\n",
       "1930  9851      1\n",
       "1931  9852      1\n",
       "1932  9853      0\n",
       "1933  9854      0\n",
       "1934  9855      0\n",
       "1935  9856      0\n",
       "1936  9857      0\n",
       "1937  9858      0\n",
       "1938  9859      0\n",
       "1939  9860      0\n",
       "1940  9861      0\n",
       "1941  9862      0\n",
       "1942  9863      1\n",
       "1943  9864      0\n",
       "1944  9865      0\n",
       "1945  9866      0\n",
       "1946  9867      0\n",
       "1947  9868      0\n",
       "1948  9869      0\n",
       "1949  9870      0\n",
       "1950  9871      1\n",
       "1951  9872      1\n",
       "1952  9873      0\n",
       "\n",
       "[1953 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"label\"] = test_data_pred\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data.drop([\"tweet\"], axis = 1, inplace = True)\n",
    "test_data.to_csv(os.path.join(TRAIN_PATH,\"testClassified.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['original_text' 'lang' 'retweet_count' 'original_author'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-556092f28860>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"original_text\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lang\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"retweet_count\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"original_author\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3940\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3778\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3779\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3780\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3811\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3812\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   4963\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4964\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 4965\u001b[1;33m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[0;32m   4966\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4967\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['original_text' 'lang' 'retweet_count' 'original_author'] not found in axis\""
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(os.path.join(TRAIN_PATH,\"testClassifiedSubmission.csv\"), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-2d9468e2d1d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
